experiments/mvff_rfcn/../../mvff_rfcn/config/config.py:160: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  exp_config = edict(yaml.load(f))
('Called with argument:', Namespace(cfg='experiments/mvff_rfcn/cfgs/resnet_v1_101_motion_vector_imagenet_vid_rfcn_end2end_ohem.yaml', frequent=100))
['motion_vector']
['mv_res_relu_output']
use ohem!
{'CLASS_AGNOSTIC': True,
 'MXNET_VERSION': 'mxnet',
 'SCALES': [(600, 1067)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': True,
          'HAS_RPN': True,
          'KEY_FRAME_INTERVAL': 12,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 0,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000,
          'max_per_image': 300,
          'test_epoch': 3},
 'TRAIN': {'ASPECT_GROUPING': True,
           'BATCH_IMAGES': 1,
           'BATCH_ROIS': -1,
           'BATCH_ROIS_OHEM': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([1., 1., 1., 1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': True,
           'ENABLE_OHEM': True,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'FLIP': True,
           'MAX_OFFSET': 0,
           'MIN_OFFSET': -9,
           'RESUME': 'ture',
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 0,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 300,
           'RPN_PRE_NMS_TOP_N': 6000,
           'SHUFFLE': True,
           'begin_epoch': 1,
           'end_epoch': 3,
           'lr': 0.00025,
           'lr_factor': 0.1,
           'lr_step': '1.333',
           'model_prefix': 'mvff_rfcn_vid',
           'momentum': 0.9,
           'warmup': False,
           'warmup_lr': 0,
           'warmup_step': 0,
           'wd': 0.0005},
 'dataset': {'NUM_CLASSES': 31,
             'dataset': 'ImageNetVID',
             'dataset_path': '/home/ssd1T_1/boyuan/ImageNetVID/ILSVRC2015',
             'image_set': 'DET_train_30classes+VID_train_15frames',
             'proposal': 'rpn',
             'root_path': '/home/ssd1T_1/boyuan/ImageNetVID',
             'test_image_set': 'VID_val_videos'},
 'default': {'frequent': 100, 'kvstore': 'device'},
 'gpus': '0, 1',
 'network': {'ANCHOR_MEANS': [0.0, 0.0, 0.0, 0.0],
             'ANCHOR_RATIOS': [0.5, 1, 2],
             'ANCHOR_SCALES': [8, 16, 32],
             'ANCHOR_STDS': [0.1, 0.1, 0.4, 0.4],
             'DFF_FEAT_DIM': 1024,
             'FIXED_PARAMS': ['conv1',
                              'bn_conv1',
                              'res2',
                              'bn2',
                              'gamma',
                              'beta'],
             'IMAGE_STRIDE': 0,
             'NORMALIZE_RPN': True,
             'NUM_ANCHORS': 9,
             'PIXEL_MEANS': array([103.06, 115.9 , 123.15]),
             'RCNN_FEAT_STRIDE': 16,
             'RPN_FEAT_STRIDE': 16,
             'pretrained': './model/pretrained_model/resnet_v1_101',
             'pretrained_epoch': 0,
             'pretrained_flow': ''},
 'output_path': './output/mvff_rfcn/imagenet_vid',
 'symbol': 'resnet_v1_101_motion_vector_rfcn'}
('image_set_index_file: ', '/home/ssd1T_1/boyuan/ImageNetVID/ILSVRC2015/ImageSets/DET_train_30classes.txt')
num_images 53639
ImageNetVID_DET_train_30classes gt roidb loaded from /home/ssd1T_1/boyuan/ImageNetVID/cache/ImageNetVID_DET_train_30classes_gt_roidb.pkl
append flipped images to roidb
('image_set_index_file: ', '/home/ssd1T_1/boyuan/ImageNetVID/ILSVRC2015/ImageSets/VID_train_15frames.txt')
num_images 57834
ImageNetVID_VID_train_15frames gt roidb loaded from /home/ssd1T_1/boyuan/ImageNetVID/cache/ImageNetVID_VID_train_15frames_gt_roidb.pkl
append flipped images to roidb
filtered 3316 roidb entries: 222946 -> 219630
providing maximum shape [('data_ref', (1, 3, 600, 1067)), ('eq_flag', (1,)), ('motion_vector', (1, 2, 608, 1072)), ('gt_boxes', (1, 100, 5))] [('label', (1, 22914)), ('bbox_target', (1, 36, 38, 67)), ('bbox_weight', (1, 36, 38, 67))]
{'bbox_target': (1, 36, 37, 67),
 'bbox_weight': (1, 36, 37, 67),
 'data_ref': (1, 3, 589, 1067),
 'eq_flag': (1,),
 'gt_boxes': (1, 1, 5),
 'im_info': (1, 3),
 'label': (1, 22311),
 'motion_vector': (1, 2, 592, 1072)}
('continue training from ', 1)
('lr', 0.00025, 'lr_epoch_diff', [0.33299999999999996], 'lr_iters', [36568])
('isinstance(step, list): ', True)
('len(step): ', 1)
Start to train model
Epoch[1] Batch [100]	Speed: 5.29 samples/sec	Train-RPNAcc=0.985825,	RPNLogLoss=0.038783,	RPNL1Loss=0.080154,	RCNNAcc=0.836750,	RCNNLogLoss=0.465610,	RCNNL1Loss=0.239281,	
Epoch[1] Batch [200]	Speed: 5.18 samples/sec	Train-RPNAcc=0.989078,	RPNLogLoss=0.032537,	RPNL1Loss=0.067706,	RCNNAcc=0.842409,	RCNNLogLoss=0.442504,	RCNNL1Loss=0.218733,	
Epoch[1] Batch [300]	Speed: 5.00 samples/sec	Train-RPNAcc=0.988113,	RPNLogLoss=0.037153,	RPNL1Loss=0.070892,	RCNNAcc=0.845359,	RCNNLogLoss=0.438328,	RCNNL1Loss=0.219100,	
